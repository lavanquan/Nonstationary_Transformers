{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/qula0496/quan/Nonstationary_Transformers/ns_models'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qula0496/quan/Nonstationary_Transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qula0496/quan/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "id_gpu = '1'\n",
    "n_users = 21\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = id_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import *\n",
    "from utils.model_utils import *\n",
    "# from utils.koopman_utils import *\n",
    "from modules.serverbase import *\n",
    "from modules.userbase import *\n",
    "from modules.servernsTransformer import *\n",
    "from modules.usernsTranformer import *\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.cuda.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['start', 'feat_static_cat', 'feat_dynamic_real', 'item_id', 'target'],\n",
       "        num_rows: 210\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['start', 'feat_static_cat', 'feat_dynamic_real', 'item_id', 'target'],\n",
       "        num_rows: 210\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['start', 'feat_static_cat', 'feat_dynamic_real', 'item_id', 'target'],\n",
       "        num_rows: 210\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"LeoTungAnh/kdd210_hourly\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10898"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset[0]['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[row['item_id']] = row['target']\n",
      "/tmp/ipykernel_4085268/2019493983.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['date'] = '2015-01-01 00:00:00'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T201</th>\n",
       "      <th>T202</th>\n",
       "      <th>T203</th>\n",
       "      <th>T204</th>\n",
       "      <th>T205</th>\n",
       "      <th>T206</th>\n",
       "      <th>T207</th>\n",
       "      <th>T208</th>\n",
       "      <th>T209</th>\n",
       "      <th>T210</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>1.468122</td>\n",
       "      <td>1.538769</td>\n",
       "      <td>-0.030617</td>\n",
       "      <td>-0.781501</td>\n",
       "      <td>-0.802695</td>\n",
       "      <td>-0.772417</td>\n",
       "      <td>-0.378809</td>\n",
       "      <td>-0.237514</td>\n",
       "      <td>-0.393948</td>\n",
       "      <td>-0.810264</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131542</td>\n",
       "      <td>-0.785538</td>\n",
       "      <td>-0.807741</td>\n",
       "      <td>-0.777464</td>\n",
       "      <td>1.493353</td>\n",
       "      <td>1.654833</td>\n",
       "      <td>-0.025571</td>\n",
       "      <td>-0.776959</td>\n",
       "      <td>-0.777464</td>\n",
       "      <td>-0.792602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>1.316855</td>\n",
       "      <td>1.449373</td>\n",
       "      <td>-0.079674</td>\n",
       "      <td>-0.773862</td>\n",
       "      <td>-0.798327</td>\n",
       "      <td>-0.767746</td>\n",
       "      <td>-0.512904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.507808</td>\n",
       "      <td>-0.803933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140836</td>\n",
       "      <td>-0.775391</td>\n",
       "      <td>-0.798327</td>\n",
       "      <td>-0.772842</td>\n",
       "      <td>1.444276</td>\n",
       "      <td>1.724601</td>\n",
       "      <td>-0.023609</td>\n",
       "      <td>-0.804443</td>\n",
       "      <td>-0.767746</td>\n",
       "      <td>-0.783036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>1.261700</td>\n",
       "      <td>1.636722</td>\n",
       "      <td>-0.061296</td>\n",
       "      <td>-0.759776</td>\n",
       "      <td>-0.780089</td>\n",
       "      <td>-0.754046</td>\n",
       "      <td>-0.639456</td>\n",
       "      <td>-0.582161</td>\n",
       "      <td>-0.597787</td>\n",
       "      <td>-0.792069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134217</td>\n",
       "      <td>-0.759776</td>\n",
       "      <td>-0.780089</td>\n",
       "      <td>-0.754046</td>\n",
       "      <td>1.501297</td>\n",
       "      <td>1.772147</td>\n",
       "      <td>-0.009210</td>\n",
       "      <td>-0.791548</td>\n",
       "      <td>-0.748838</td>\n",
       "      <td>-0.769672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>1.487590</td>\n",
       "      <td>1.831615</td>\n",
       "      <td>-0.022891</td>\n",
       "      <td>-0.730291</td>\n",
       "      <td>-0.753942</td>\n",
       "      <td>-0.721690</td>\n",
       "      <td>-0.646435</td>\n",
       "      <td>-0.560429</td>\n",
       "      <td>-0.555053</td>\n",
       "      <td>-0.765768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114272</td>\n",
       "      <td>-0.733516</td>\n",
       "      <td>-0.753942</td>\n",
       "      <td>-0.732441</td>\n",
       "      <td>0.525398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.270158</td>\n",
       "      <td>-0.744267</td>\n",
       "      <td>-0.678687</td>\n",
       "      <td>-0.748567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>1.842409</td>\n",
       "      <td>2.225288</td>\n",
       "      <td>0.150884</td>\n",
       "      <td>-0.702879</td>\n",
       "      <td>-0.723452</td>\n",
       "      <td>-0.694879</td>\n",
       "      <td>-0.632018</td>\n",
       "      <td>-0.500582</td>\n",
       "      <td>-0.454865</td>\n",
       "      <td>-0.741738</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066271</td>\n",
       "      <td>-0.707451</td>\n",
       "      <td>-0.729166</td>\n",
       "      <td>-0.717737</td>\n",
       "      <td>-0.672020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.569157</td>\n",
       "      <td>-0.743453</td>\n",
       "      <td>-0.557728</td>\n",
       "      <td>-0.723452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           T1        T2        T3        T4        T5  \\\n",
       "date                                                                    \n",
       "2015-01-01 00:00:00  1.468122  1.538769 -0.030617 -0.781501 -0.802695   \n",
       "2015-01-01 00:00:00  1.316855  1.449373 -0.079674 -0.773862 -0.798327   \n",
       "2015-01-01 00:00:00  1.261700  1.636722 -0.061296 -0.759776 -0.780089   \n",
       "2015-01-01 00:00:00  1.487590  1.831615 -0.022891 -0.730291 -0.753942   \n",
       "2015-01-01 00:00:00  1.842409  2.225288  0.150884 -0.702879 -0.723452   \n",
       "\n",
       "                           T6        T7        T8        T9       T10  ...  \\\n",
       "date                                                                   ...   \n",
       "2015-01-01 00:00:00 -0.772417 -0.378809 -0.237514 -0.393948 -0.810264  ...   \n",
       "2015-01-01 00:00:00 -0.767746 -0.512904  0.000000 -0.507808 -0.803933  ...   \n",
       "2015-01-01 00:00:00 -0.754046 -0.639456 -0.582161 -0.597787 -0.792069  ...   \n",
       "2015-01-01 00:00:00 -0.721690 -0.646435 -0.560429 -0.555053 -0.765768  ...   \n",
       "2015-01-01 00:00:00 -0.694879 -0.632018 -0.500582 -0.454865 -0.741738  ...   \n",
       "\n",
       "                         T201      T202      T203      T204      T205  \\\n",
       "date                                                                    \n",
       "2015-01-01 00:00:00 -0.131542 -0.785538 -0.807741 -0.777464  1.493353   \n",
       "2015-01-01 00:00:00 -0.140836 -0.775391 -0.798327 -0.772842  1.444276   \n",
       "2015-01-01 00:00:00 -0.134217 -0.759776 -0.780089 -0.754046  1.501297   \n",
       "2015-01-01 00:00:00 -0.114272 -0.733516 -0.753942 -0.732441  0.525398   \n",
       "2015-01-01 00:00:00 -0.066271 -0.707451 -0.729166 -0.717737 -0.672020   \n",
       "\n",
       "                         T206      T207      T208      T209      T210  \n",
       "date                                                                   \n",
       "2015-01-01 00:00:00  1.654833 -0.025571 -0.776959 -0.777464 -0.792602  \n",
       "2015-01-01 00:00:00  1.724601 -0.023609 -0.804443 -0.767746 -0.783036  \n",
       "2015-01-01 00:00:00  1.772147 -0.009210 -0.791548 -0.748838 -0.769672  \n",
       "2015-01-01 00:00:00  0.000000 -0.270158 -0.744267 -0.678687 -0.748567  \n",
       "2015-01-01 00:00:00  0.000000 -0.569157 -0.743453 -0.557728 -0.723452  \n",
       "\n",
       "[5 rows x 210 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list of dictionaries, where each dictionary represents a row in the DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for row in test_dataset:\n",
    "  df[row['item_id']] = row['target']\n",
    "\n",
    "df['date'] = '2015-01-01 00:00:00'\n",
    "df = df.set_index(\"date\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the DataFrame to a CSV file\n",
    "# df.to_csv('/home/qula0496/quan/Nonstationary_Transformers/dataset/kdd/kdd.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10898, 210)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kdd.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ns_models.ns_TransformerConfig import NS_TransformerConfig\n",
    "user_num_ts = int(df.shape[1] / n_users)\n",
    "args = NS_TransformerConfig()\n",
    "args.devices = id_gpu\n",
    "args.enc_in = user_num_ts\n",
    "args.dec_in = user_num_ts\n",
    "args.c_out = user_num_ts\n",
    "args.root_path = './dataset/kdd/'\n",
    "args.data_path = 'kdd.csv'\n",
    "args.model_id = 'kdd_96_96'\n",
    "args.data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data_provider.data_factory import *\n",
    "from data_provider.data_loader import *\n",
    "\n",
    "test_data, test_loader = data_provider(args, flag='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_list = []\n",
    "server_data_list = []\n",
    "for i in range(n_users):\n",
    "    train_data, train_loader = data_provider(args, flag='train', start=i*user_num_ts+1, end=min(user_num_ts*(i+1)+1, df.shape[1]+1))\n",
    "    test_data, test_loader = data_provider(args, flag='test', start=i*user_num_ts+1, end=min(user_num_ts*(i+1)+1, df.shape[1]+1))\n",
    "    # user_data = train_set.filter(lambda e, idx: idx>=(i*user_num_ts) and idx < user_num_ts*(i+1), with_indices=True)\n",
    "    user_data_list.append(train_loader)\n",
    "    server_data_list.append(test_loader)\n",
    "    # print(train_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (enc_embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(10, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=4, out_features=64, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dec_embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(10, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=4, out_features=64, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attn_layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (attention): AttentionLayer(\n",
       "          (inner_attention): DSAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x DecoderLayer(\n",
       "        (self_attention): AttentionLayer(\n",
       "          (inner_attention): DSAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (cross_attention): AttentionLayer(\n",
       "          (inner_attention): DSAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       "  (tau_learner): Projector(\n",
       "    (series_conv): Conv1d(96, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    (backbone): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (delta_learner): Projector(\n",
       "    (series_conv): Conv1d(96, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    (backbone): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=96, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ns_models import ns_Transformer\n",
    "server_model = ns_Transformer.Model(configs=args)\n",
    "server_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkenlvq\u001b[0m (\u001b[33mquanla\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2d052f4faf458a972ceffb0b642a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011132600996643306, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/qula0496/quan/Nonstationary_Transformers/wandb/run-20240611_143855-0egec35d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20KDD%20dataset/runs/0egec35d' target=\"_blank\">Federated Non-Stationary Transformer on KDD dataset</a></strong> to <a href='https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20KDD%20dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20KDD%20dataset' target=\"_blank\">https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20KDD%20dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20KDD%20dataset/runs/0egec35d' target=\"_blank\">https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20KDD%20dataset/runs/0egec35d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "LR = 1e-3\n",
    "GLOBAL_EPOCHS = 30\n",
    "LOCAL_EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "L2_PENALTY = 0.0\n",
    "USER_RATIO = 0.1\n",
    "run = wandb.init(\n",
    "    # project name\n",
    "    project=\"Federated Non-Stationary Transformer on KDD dataset\",\n",
    "    # experiment name\n",
    "    name=f\"Federated Non-Stationary Transformer on KDD dataset\",\n",
    "    # Hyperparams\n",
    "    config={\n",
    "        \"dataset\": \"KDD210\",\n",
    "        \"preprocess_type\": \"std\",\n",
    "        \"num_user\": n_users,\n",
    "        \"learning_rate\": LR,\n",
    "        \"global_epochs\": GLOBAL_EPOCHS,\n",
    "        \"local_epochs\": LOCAL_EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"num_gpus\": NUM_GPUS,\n",
    "        \"user_ratio\": USER_RATIO,\n",
    "        \"l2_penalty\": L2_PENALTY,\n",
    "        \"total_time_series\": 210,\n",
    "        \"detrending_data\": \"No\"\n",
    "    })\n",
    "\n",
    "config_wanb = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab01f0bb0>\n",
      "Epoch: 1 cost time: 109.61023426055908\n",
      "Epoch: 2 cost time: 120.19557237625122\n",
      "Epoch: 3 cost time: 125.92531204223633\n",
      "Epoch: 4 cost time: 127.20612263679504\n",
      "Epoch: 5 cost time: 135.97613835334778\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02c3d90>\n",
      "Epoch: 1 cost time: 137.31322026252747\n",
      "Epoch: 2 cost time: 136.08390998840332\n",
      "Epoch: 3 cost time: 136.84031224250793\n",
      "Epoch: 4 cost time: 135.89531183242798\n",
      "Epoch: 5 cost time: 135.98951125144958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   3%|▎         | 1/30 [25:03<12:06:40, 1503.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa903735b0>\n",
      "Epoch: 1 cost time: 137.33275198936462\n",
      "Epoch: 2 cost time: 136.01645255088806\n",
      "Epoch: 3 cost time: 137.25294423103333\n",
      "Epoch: 4 cost time: 135.42034363746643\n",
      "Epoch: 5 cost time: 137.05279803276062\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab023eec0>\n",
      "Epoch: 1 cost time: 136.87971878051758\n",
      "Epoch: 2 cost time: 135.46546268463135\n",
      "Epoch: 3 cost time: 137.0388855934143\n",
      "Epoch: 4 cost time: 137.49792313575745\n",
      "Epoch: 5 cost time: 136.85776543617249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   7%|▋         | 2/30 [51:10<11:59:09, 1541.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02c3d90>\n",
      "Epoch: 1 cost time: 136.26390314102173\n",
      "Epoch: 2 cost time: 136.2125232219696\n",
      "Epoch: 3 cost time: 137.3337528705597\n",
      "Epoch: 4 cost time: 136.70087146759033\n",
      "Epoch: 5 cost time: 137.31641912460327\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02d74c0>\n",
      "Epoch: 1 cost time: 136.40129733085632\n",
      "Epoch: 2 cost time: 135.81722474098206\n",
      "Epoch: 3 cost time: 135.9063220024109\n",
      "Epoch: 4 cost time: 136.24763584136963\n",
      "Epoch: 5 cost time: 136.8204483985901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  10%|█         | 3/30 [1:17:18<11:38:53, 1553.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab023fc40>\n",
      "Epoch: 1 cost time: 136.48635149002075\n",
      "Epoch: 2 cost time: 137.43883061408997\n",
      "Epoch: 3 cost time: 136.56391382217407\n",
      "Epoch: 4 cost time: 137.70266461372375\n",
      "Epoch: 5 cost time: 136.24508786201477\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02586a0>\n",
      "Epoch: 1 cost time: 137.0313766002655\n",
      "Epoch: 2 cost time: 135.27483105659485\n",
      "Epoch: 3 cost time: 136.38743090629578\n",
      "Epoch: 4 cost time: 137.18206524848938\n",
      "Epoch: 5 cost time: 135.92081499099731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  13%|█▎        | 4/30 [1:43:25<11:15:28, 1558.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02c3c70>\n",
      "Epoch: 1 cost time: 135.2541537284851\n",
      "Epoch: 2 cost time: 137.16155433654785\n",
      "Epoch: 3 cost time: 137.5112509727478\n",
      "Epoch: 4 cost time: 135.7739133834839\n",
      "Epoch: 5 cost time: 136.4589192867279\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab025b370>\n",
      "Epoch: 1 cost time: 135.67786645889282\n",
      "Epoch: 2 cost time: 137.21036458015442\n",
      "Epoch: 3 cost time: 137.9333233833313\n",
      "Epoch: 4 cost time: 136.60305166244507\n",
      "Epoch: 5 cost time: 136.3861038684845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  17%|█▋        | 5/30 [2:09:33<10:50:49, 1561.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab01f2380>\n",
      "Epoch: 1 cost time: 136.50003623962402\n",
      "Epoch: 2 cost time: 136.80974984169006\n",
      "Epoch: 3 cost time: 137.4209988117218\n",
      "Epoch: 4 cost time: 136.22075629234314\n",
      "Epoch: 5 cost time: 136.19310855865479\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab01f0bb0>\n",
      "Epoch: 1 cost time: 136.8179750442505\n",
      "Epoch: 2 cost time: 137.24835205078125\n",
      "Epoch: 3 cost time: 136.00820326805115\n",
      "Epoch: 4 cost time: 137.13856434822083\n",
      "Epoch: 5 cost time: 137.07954740524292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  20%|██        | 6/30 [2:35:44<10:25:59, 1564.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab025b010>\n",
      "Epoch: 1 cost time: 138.04414868354797\n",
      "Epoch: 2 cost time: 136.70217514038086\n",
      "Epoch: 3 cost time: 136.96712231636047\n",
      "Epoch: 4 cost time: 135.0658745765686\n",
      "Epoch: 5 cost time: 138.14327216148376\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02d4190>\n",
      "Epoch: 1 cost time: 135.3306655883789\n",
      "Epoch: 2 cost time: 138.32368636131287\n",
      "Epoch: 3 cost time: 137.54567790031433\n",
      "Epoch: 4 cost time: 136.3283965587616\n",
      "Epoch: 5 cost time: 135.7775113582611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  23%|██▎       | 7/30 [3:01:54<10:00:32, 1566.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab025b370>\n",
      "Epoch: 1 cost time: 137.3141279220581\n",
      "Epoch: 2 cost time: 137.04649448394775\n",
      "Epoch: 3 cost time: 136.98659539222717\n",
      "Epoch: 4 cost time: 136.04659843444824\n",
      "Epoch: 5 cost time: 136.9470729827881\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa90303cd0>\n",
      "Epoch: 1 cost time: 136.68459367752075\n",
      "Epoch: 2 cost time: 135.85959434509277\n",
      "Epoch: 3 cost time: 137.5661392211914\n",
      "Epoch: 4 cost time: 136.4782576560974\n",
      "Epoch: 5 cost time: 137.0952877998352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  27%|██▋       | 8/30 [3:28:03<9:34:43, 1567.42s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa9046d960>\n",
      "Epoch: 1 cost time: 137.11892461776733\n",
      "Epoch: 2 cost time: 136.2929174900055\n",
      "Epoch: 3 cost time: 135.94573497772217\n",
      "Epoch: 4 cost time: 137.37022042274475\n",
      "Epoch: 5 cost time: 136.12600231170654\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab003c2e0>\n",
      "Epoch: 1 cost time: 136.6813108921051\n",
      "Epoch: 2 cost time: 137.28646731376648\n",
      "Epoch: 3 cost time: 135.3510706424713\n",
      "Epoch: 4 cost time: 136.9342041015625\n",
      "Epoch: 5 cost time: 136.6902196407318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  30%|███       | 9/30 [3:54:11<9:08:39, 1567.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab01f2380>\n",
      "Epoch: 1 cost time: 135.5401964187622\n",
      "Epoch: 2 cost time: 137.22380185127258\n",
      "Epoch: 3 cost time: 136.8480727672577\n",
      "Epoch: 4 cost time: 136.31077814102173\n",
      "Epoch: 5 cost time: 136.25021409988403\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02c3af0>\n",
      "Epoch: 1 cost time: 136.07580280303955\n",
      "Epoch: 2 cost time: 137.56234526634216\n",
      "Epoch: 3 cost time: 136.4246323108673\n",
      "Epoch: 4 cost time: 136.51080083847046\n",
      "Epoch: 5 cost time: 138.75349688529968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  33%|███▎      | 10/30 [4:20:21<8:42:45, 1568.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa9046d960>\n",
      "Epoch: 1 cost time: 136.5516972541809\n",
      "Epoch: 2 cost time: 135.88934993743896\n",
      "Epoch: 3 cost time: 137.5274214744568\n",
      "Epoch: 4 cost time: 137.23798942565918\n",
      "Epoch: 5 cost time: 136.80612516403198\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab01f0bb0>\n",
      "Epoch: 1 cost time: 135.32797193527222\n",
      "Epoch: 2 cost time: 136.02418184280396\n",
      "Epoch: 3 cost time: 136.3488004207611\n",
      "Epoch: 4 cost time: 135.66654419898987\n",
      "Epoch: 5 cost time: 136.1834888458252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  37%|███▋      | 11/30 [4:46:26<8:16:17, 1567.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab025bc40>\n",
      "Epoch: 1 cost time: 136.66447162628174\n",
      "Epoch: 2 cost time: 135.1310465335846\n",
      "Epoch: 3 cost time: 134.66173386573792\n",
      "Epoch: 4 cost time: 136.1908974647522\n",
      "Epoch: 5 cost time: 135.3889136314392\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02c3c70>\n",
      "Epoch: 1 cost time: 136.824875831604\n",
      "Epoch: 2 cost time: 137.15343570709229\n",
      "Epoch: 3 cost time: 137.25060367584229\n",
      "Epoch: 4 cost time: 137.5051326751709\n",
      "Epoch: 5 cost time: 137.6793291568756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  40%|████      | 12/30 [5:12:32<7:50:03, 1566.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa903735b0>\n",
      "Epoch: 1 cost time: 137.16278672218323\n",
      "Epoch: 2 cost time: 136.8233757019043\n",
      "Epoch: 3 cost time: 137.4490008354187\n",
      "Epoch: 4 cost time: 136.34776639938354\n",
      "Epoch: 5 cost time: 135.78240776062012\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02586a0>\n",
      "Epoch: 1 cost time: 136.83773469924927\n",
      "Epoch: 2 cost time: 137.07439613342285\n",
      "Epoch: 3 cost time: 137.98298954963684\n",
      "Epoch: 4 cost time: 137.81026601791382\n",
      "Epoch: 5 cost time: 135.90609884262085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  43%|████▎     | 13/30 [5:38:43<7:24:21, 1568.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab003c2e0>\n",
      "Epoch: 1 cost time: 138.46525478363037\n",
      "Epoch: 2 cost time: 137.646586894989\n",
      "Epoch: 3 cost time: 135.9947328567505\n",
      "Epoch: 4 cost time: 137.64856886863708\n",
      "Epoch: 5 cost time: 135.76166772842407\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab023fc40>\n",
      "Epoch: 1 cost time: 136.33519411087036\n",
      "Epoch: 2 cost time: 137.38982152938843\n",
      "Epoch: 3 cost time: 137.01318454742432\n",
      "Epoch: 4 cost time: 137.87904477119446\n",
      "Epoch: 5 cost time: 136.83657002449036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  47%|████▋     | 14/30 [6:04:55<6:58:27, 1569.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab023eec0>\n",
      "Epoch: 1 cost time: 136.38513660430908\n",
      "Epoch: 2 cost time: 135.23805713653564\n",
      "Epoch: 3 cost time: 136.2540979385376\n",
      "Epoch: 4 cost time: 136.75037097930908\n",
      "Epoch: 5 cost time: 137.14327239990234\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab025b370>\n",
      "Epoch: 1 cost time: 137.06738018989563\n",
      "Epoch: 2 cost time: 136.78449892997742\n",
      "Epoch: 3 cost time: 138.40118503570557\n",
      "Epoch: 4 cost time: 136.20890545845032\n",
      "Epoch: 5 cost time: 136.73344683647156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  50%|█████     | 15/30 [6:31:04<6:32:18, 1569.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab025b010>\n",
      "Epoch: 1 cost time: 137.35841345787048\n",
      "Epoch: 2 cost time: 135.97219944000244\n",
      "Epoch: 3 cost time: 134.93328285217285\n",
      "Epoch: 4 cost time: 136.55649304389954\n",
      "Epoch: 5 cost time: 137.35189628601074\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa90303c70>\n",
      "Epoch: 1 cost time: 137.52345418930054\n",
      "Epoch: 2 cost time: 135.5540165901184\n",
      "Epoch: 3 cost time: 136.25206232070923\n",
      "Epoch: 4 cost time: 135.37955784797668\n",
      "Epoch: 5 cost time: 135.83234858512878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  53%|█████▎    | 16/30 [6:57:08<6:05:48, 1567.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab025b370>\n",
      "Epoch: 1 cost time: 136.26289176940918\n",
      "Epoch: 2 cost time: 136.90472149848938\n",
      "Epoch: 3 cost time: 136.4843339920044\n",
      "Epoch: 4 cost time: 136.6268756389618\n",
      "Epoch: 5 cost time: 137.93404722213745\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa903735b0>\n",
      "Epoch: 1 cost time: 135.9993224143982\n",
      "Epoch: 2 cost time: 137.02705931663513\n",
      "Epoch: 3 cost time: 136.58044528961182\n",
      "Epoch: 4 cost time: 136.52706098556519\n",
      "Epoch: 5 cost time: 138.1159029006958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  57%|█████▋    | 17/30 [7:23:19<5:39:51, 1568.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02d74c0>\n",
      "Epoch: 1 cost time: 137.88844275474548\n",
      "Epoch: 2 cost time: 136.18928480148315\n",
      "Epoch: 3 cost time: 137.27392554283142\n",
      "Epoch: 4 cost time: 135.686176776886\n",
      "Epoch: 5 cost time: 136.00052404403687\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa90303c70>\n",
      "Epoch: 1 cost time: 132.46464943885803\n",
      "Epoch: 2 cost time: 122.96487307548523\n",
      "Epoch: 3 cost time: 123.80990242958069\n",
      "Epoch: 4 cost time: 124.26981997489929\n",
      "Epoch: 5 cost time: 123.84754014015198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  60%|██████    | 18/30 [7:48:11<5:09:09, 1545.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab025b010>\n",
      "Epoch: 1 cost time: 125.18088817596436\n",
      "Epoch: 2 cost time: 123.87368679046631\n",
      "Epoch: 3 cost time: 124.54988694190979\n",
      "Epoch: 4 cost time: 124.70711612701416\n",
      "Epoch: 5 cost time: 124.45413565635681\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab003c2e0>\n",
      "Epoch: 1 cost time: 124.57509779930115\n",
      "Epoch: 2 cost time: 124.0705463886261\n",
      "Epoch: 3 cost time: 124.91030764579773\n",
      "Epoch: 4 cost time: 124.5022988319397\n",
      "Epoch: 5 cost time: 124.14014172554016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  63%|██████▎   | 19/30 [8:11:59<4:36:54, 1510.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab025b010>\n",
      "Epoch: 1 cost time: 124.4031629562378\n",
      "Epoch: 2 cost time: 123.2477159500122\n",
      "Epoch: 3 cost time: 123.52330446243286\n",
      "Epoch: 4 cost time: 125.6399450302124\n",
      "Epoch: 5 cost time: 124.51731038093567\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab023fc40>\n",
      "Epoch: 1 cost time: 124.29112768173218\n",
      "Epoch: 2 cost time: 123.77679753303528\n",
      "Epoch: 3 cost time: 123.7221508026123\n",
      "Epoch: 4 cost time: 123.98108077049255\n",
      "Epoch: 5 cost time: 123.3758864402771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  67%|██████▋   | 20/30 [8:35:43<4:07:23, 1484.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab01f0bb0>\n",
      "Epoch: 1 cost time: 124.77288103103638\n",
      "Epoch: 2 cost time: 124.19221544265747\n",
      "Epoch: 3 cost time: 124.00396370887756\n",
      "Epoch: 4 cost time: 124.63596439361572\n",
      "Epoch: 5 cost time: 124.42523145675659\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02c3d90>\n",
      "Epoch: 1 cost time: 125.3038341999054\n",
      "Epoch: 2 cost time: 123.83979821205139\n",
      "Epoch: 3 cost time: 123.80015587806702\n",
      "Epoch: 4 cost time: 124.12226915359497\n",
      "Epoch: 5 cost time: 124.99074673652649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  70%|███████   | 21/30 [8:59:30<3:40:03, 1467.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa903736a0>\n",
      "Epoch: 1 cost time: 123.70169568061829\n",
      "Epoch: 2 cost time: 123.71005082130432\n",
      "Epoch: 3 cost time: 124.53761339187622\n",
      "Epoch: 4 cost time: 123.32409954071045\n",
      "Epoch: 5 cost time: 123.69987154006958\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab01f0bb0>\n",
      "Epoch: 1 cost time: 123.56855583190918\n",
      "Epoch: 2 cost time: 123.79308867454529\n",
      "Epoch: 3 cost time: 123.94020223617554\n",
      "Epoch: 4 cost time: 124.57405138015747\n",
      "Epoch: 5 cost time: 123.98619747161865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  73%|███████▎  | 22/30 [9:23:12<3:13:49, 1453.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa903736a0>\n",
      "Epoch: 1 cost time: 124.56473851203918\n",
      "Epoch: 2 cost time: 124.54804754257202\n",
      "Epoch: 3 cost time: 124.02254748344421\n",
      "Epoch: 4 cost time: 123.24672818183899\n",
      "Epoch: 5 cost time: 123.93650460243225\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa9024bb20>\n",
      "Epoch: 1 cost time: 124.08820128440857\n",
      "Epoch: 2 cost time: 124.62065291404724\n",
      "Epoch: 3 cost time: 124.0618302822113\n",
      "Epoch: 4 cost time: 122.90492081642151\n",
      "Epoch: 5 cost time: 124.37480878829956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  77%|███████▋  | 23/30 [9:46:55<2:48:31, 1444.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab003c2e0>\n",
      "Epoch: 1 cost time: 123.7405993938446\n",
      "Epoch: 2 cost time: 123.76138377189636\n",
      "Epoch: 3 cost time: 122.9624228477478\n",
      "Epoch: 4 cost time: 123.64500451087952\n",
      "Epoch: 5 cost time: 123.37504601478577\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02c3d90>\n",
      "Epoch: 1 cost time: 124.21851015090942\n",
      "Epoch: 2 cost time: 124.33049702644348\n",
      "Epoch: 3 cost time: 125.15661406517029\n",
      "Epoch: 4 cost time: 123.8809118270874\n",
      "Epoch: 5 cost time: 123.28062796592712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  80%|████████  | 24/30 [10:10:38<2:23:47, 1437.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa9046d960>\n",
      "Epoch: 1 cost time: 125.34915661811829\n",
      "Epoch: 2 cost time: 123.36010241508484\n",
      "Epoch: 3 cost time: 124.09092903137207\n",
      "Epoch: 4 cost time: 124.6315770149231\n",
      "Epoch: 5 cost time: 124.72689485549927\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab003c2e0>\n",
      "Epoch: 1 cost time: 123.41392374038696\n",
      "Epoch: 2 cost time: 124.20264792442322\n",
      "Epoch: 3 cost time: 124.21957278251648\n",
      "Epoch: 4 cost time: 124.53045582771301\n",
      "Epoch: 5 cost time: 124.3580219745636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  83%|████████▎ | 25/30 [10:34:24<1:59:32, 1434.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02d74c0>\n",
      "Epoch: 1 cost time: 124.69668245315552\n",
      "Epoch: 2 cost time: 124.00851917266846\n",
      "Epoch: 3 cost time: 123.28205370903015\n",
      "Epoch: 4 cost time: 124.33127737045288\n",
      "Epoch: 5 cost time: 124.38805174827576\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab02d4190>\n",
      "Epoch: 1 cost time: 124.53347778320312\n",
      "Epoch: 2 cost time: 124.92598676681519\n",
      "Epoch: 3 cost time: 124.50575423240662\n",
      "Epoch: 4 cost time: 124.88488721847534\n",
      "Epoch: 5 cost time: 124.69500494003296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  87%|████████▋ | 26/30 [10:58:12<1:35:30, 1432.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab025b370>\n",
      "Epoch: 1 cost time: 124.32951235771179\n",
      "Epoch: 2 cost time: 126.20797491073608\n",
      "Epoch: 3 cost time: 125.58674812316895\n",
      "Epoch: 4 cost time: 123.98162961006165\n",
      "Epoch: 5 cost time: 124.24998164176941\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab023fc40>\n",
      "Epoch: 1 cost time: 124.22978043556213\n",
      "Epoch: 2 cost time: 122.82171630859375\n",
      "Epoch: 3 cost time: 124.65028643608093\n",
      "Epoch: 4 cost time: 124.16041970252991\n",
      "Epoch: 5 cost time: 124.93414187431335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  90%|█████████ | 27/30 [11:21:51<1:11:25, 1428.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa9024bb20>\n",
      "Epoch: 1 cost time: 111.34242582321167\n",
      "Epoch: 2 cost time: 112.43688225746155\n",
      "Epoch: 3 cost time: 111.62532782554626\n",
      "Epoch: 4 cost time: 111.97165179252625\n",
      "Epoch: 5 cost time: 111.08921360969543\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa903736a0>\n",
      "Epoch: 1 cost time: 111.13398885726929\n",
      "Epoch: 2 cost time: 112.26306986808777\n",
      "Epoch: 3 cost time: 112.01122045516968\n",
      "Epoch: 4 cost time: 111.77609276771545\n",
      "Epoch: 5 cost time: 111.29513502120972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  93%|█████████▎| 28/30 [11:43:13<46:09, 1384.54s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab025bc40>\n",
      "Epoch: 1 cost time: 111.51515579223633\n",
      "Epoch: 2 cost time: 112.93570351600647\n",
      "Epoch: 3 cost time: 110.99412035942078\n",
      "Epoch: 4 cost time: 111.52454662322998\n",
      "Epoch: 5 cost time: 111.48313283920288\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efa903735b0>\n",
      "Epoch: 1 cost time: 110.97553443908691\n",
      "Epoch: 2 cost time: 112.39423704147339\n",
      "Epoch: 3 cost time: 111.96345067024231\n",
      "Epoch: 4 cost time: 111.09145307540894\n",
      "Epoch: 5 cost time: 111.5783338546753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  97%|█████████▋| 29/30 [12:04:34<22:33, 1353.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab023eec0>\n",
      "Epoch: 1 cost time: 111.61570167541504\n",
      "Epoch: 2 cost time: 112.13050293922424\n",
      "Epoch: 3 cost time: 111.16899728775024\n",
      "Epoch: 4 cost time: 111.28393530845642\n",
      "Epoch: 5 cost time: 111.10040307044983\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7efab025b010>\n",
      "Epoch: 1 cost time: 112.63302397727966\n",
      "Epoch: 2 cost time: 111.36507821083069\n",
      "Epoch: 3 cost time: 112.27955365180969\n",
      "Epoch: 4 cost time: 111.89357447624207\n",
      "Epoch: 5 cost time: 112.50502443313599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 30/30 [12:25:56<00:00, 1491.88s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "\n",
    "server = ServerNsTransformer(model=server_model, test_loader=server_data_list)\n",
    "\n",
    "user_list = []\n",
    "\n",
    "# Create users\n",
    "for i in range(config_wanb.num_user):\n",
    "    user_i = UserNsTransformer(train_loader=user_data_list[i], model=server_model, user_id=i, local_epochs=config_wanb.local_epochs)\n",
    "    user_list.append(user_i)\n",
    "\n",
    "for _ in tqdm(range(config_wanb.global_epochs), desc=f\"Progress\"):\n",
    "    # Distribute initial model to users\n",
    "    server.distribute_model(user_list)\n",
    "    \n",
    "    # Sub-sample users\n",
    "    sub_user_list = random.sample(user_list, int(config_wanb.user_ratio * config_wanb.num_user))\n",
    "\n",
    "    # Check the sub-sampled user and train model\n",
    "    users_loss = 0.0\n",
    "    for user in sub_user_list:\n",
    "        print(user)\n",
    "        user_loss = user.user_train(args)\n",
    "        users_loss += user_loss\n",
    "    # Aggregate weights on server\n",
    "    server.aggregate_weights(sub_user_list)\n",
    "\n",
    "    # Calulate avg loss on selected users\n",
    "    train_loss =  users_loss / len(sub_user_list)\n",
    "\n",
    "    total_mae = []\n",
    "    total_mse = []\n",
    "    for test_loader in server.test_loader:    \n",
    "        mae, mse, rmse, mape, mspe = server.model_eval(args=args, test_loader=test_loader)\n",
    "        total_mae.append(mae)\n",
    "        total_mse.append(mse)\n",
    "    \n",
    "    wandb.log({\"train_loss\": train_loss, \"mae\": sum(total_mae)/len(total_mae), 'rmse': sqrt(sum(total_mse)/len(total_mse))})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
