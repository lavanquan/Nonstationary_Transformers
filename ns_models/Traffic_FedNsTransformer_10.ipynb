{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/qula0496/quan/Nonstationary_Transformers/ns_models'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qula0496/quan/Nonstationary_Transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qula0496/quan/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "id_gpu = '3'\n",
    "n_users = 10\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = id_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import *\n",
    "from utils.model_utils import *\n",
    "# from utils.koopman_utils import *\n",
    "from modules.serverbase import *\n",
    "from modules.userbase import *\n",
    "from modules.servernsTransformer import *\n",
    "from modules.usernsTranformer import *\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.cuda.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ts = 862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files not exist\n",
      "/home/qula0496/quan/Nonstationary_Transformers/utils/data_utils.py\n",
      "data loaded..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17544, 862)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the dataset\n",
    "download_traffic_dataset()\n",
    "\n",
    "# Clean the dataset\n",
    "traffic_data = clean_traffic(num_ts=num_ts)\n",
    "traffic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MT_001</th>\n",
       "      <th>MT_002</th>\n",
       "      <th>MT_003</th>\n",
       "      <th>MT_004</th>\n",
       "      <th>MT_005</th>\n",
       "      <th>MT_006</th>\n",
       "      <th>MT_007</th>\n",
       "      <th>MT_008</th>\n",
       "      <th>MT_009</th>\n",
       "      <th>MT_010</th>\n",
       "      <th>...</th>\n",
       "      <th>MT_853</th>\n",
       "      <th>MT_854</th>\n",
       "      <th>MT_855</th>\n",
       "      <th>MT_856</th>\n",
       "      <th>MT_857</th>\n",
       "      <th>MT_858</th>\n",
       "      <th>MT_859</th>\n",
       "      <th>MT_860</th>\n",
       "      <th>MT_861</th>\n",
       "      <th>MT_862</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00</th>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00</th>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00</th>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 04:00:00</th>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MT_001  MT_002  MT_003  MT_004  MT_005  MT_006  MT_007  \\\n",
       "time                                                                          \n",
       "2015-01-01 00:00:00  0.0048  0.0146  0.0289  0.0142  0.0064  0.0232  0.0162   \n",
       "2015-01-01 01:00:00  0.0072  0.0148  0.0350  0.0174  0.0084  0.0240  0.0201   \n",
       "2015-01-01 02:00:00  0.0040  0.0101  0.0267  0.0124  0.0049  0.0170  0.0127   \n",
       "2015-01-01 03:00:00  0.0039  0.0060  0.0218  0.0090  0.0029  0.0118  0.0088   \n",
       "2015-01-01 04:00:00  0.0042  0.0055  0.0191  0.0082  0.0024  0.0095  0.0064   \n",
       "\n",
       "                     MT_008  MT_009  MT_010  ...  MT_853  MT_854  MT_855  \\\n",
       "time                                         ...                           \n",
       "2015-01-01 00:00:00  0.0242  0.0341  0.0375  ...  0.0051  0.0051  0.0074   \n",
       "2015-01-01 01:00:00  0.0338  0.0434  0.0381  ...  0.0036  0.0036  0.0107   \n",
       "2015-01-01 02:00:00  0.0255  0.0332  0.0309  ...  0.0030  0.0030  0.0043   \n",
       "2015-01-01 03:00:00  0.0163  0.0211  0.0199  ...  0.0033  0.0033  0.0019   \n",
       "2015-01-01 04:00:00  0.0087  0.0144  0.0226  ...  0.0049  0.0049  0.0011   \n",
       "\n",
       "                     MT_856  MT_857  MT_858  MT_859  MT_860  MT_861  MT_862  \n",
       "time                                                                         \n",
       "2015-01-01 00:00:00  0.0079  0.0051  0.0051  0.0339  0.0051  0.0100  0.0121  \n",
       "2015-01-01 01:00:00  0.0058  0.0036  0.0036  0.0348  0.0036  0.0087  0.0136  \n",
       "2015-01-01 02:00:00  0.0050  0.0030  0.0030  0.0327  0.0030  0.0061  0.0107  \n",
       "2015-01-01 03:00:00  0.0052  0.0033  0.0033  0.0292  0.0033  0.0040  0.0071  \n",
       "2015-01-01 04:00:00  0.0071  0.0049  0.0049  0.0264  0.0049  0.0040  0.0039  \n",
       "\n",
       "[5 rows x 862 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prompt: write pandas to csv\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Save the DataFrame to a CSV file\n",
    "# traffic_data.to_csv('/home/qula0496/quan/Nonstationary_Transformers/dataset/traffic/traffic.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'traffic.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ns_models.ns_TransformerConfig import NS_TransformerConfig\n",
    "user_num_ts = int(traffic_data.shape[1] / n_users)\n",
    "args = NS_TransformerConfig()\n",
    "args.devices = id_gpu\n",
    "args.enc_in = user_num_ts\n",
    "args.dec_in = user_num_ts\n",
    "args.c_out = user_num_ts\n",
    "args.root_path = './dataset/traffic/'\n",
    "args.data_path = 'traffic.csv'\n",
    "args.model_id = 'traffic_96_96'\n",
    "args.data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data_provider.data_factory import *\n",
    "from data_provider.data_loader import *\n",
    "\n",
    "test_data, test_loader = data_provider(args, flag='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data_provider.data_loader.Dataset_ETT_hour at 0x7f8f7867b070>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_list = []\n",
    "server_data_list = []\n",
    "for i in range(n_users):\n",
    "    train_data, train_loader = data_provider(args, flag='train', start=i*user_num_ts+1, end=min(user_num_ts*(i+1)+1, traffic_data.shape[1]+1))\n",
    "    test_data, test_loader = data_provider(args, flag='test', start=i*user_num_ts+1, end=min(user_num_ts*(i+1)+1, traffic_data.shape[1]+1))\n",
    "    # user_data = train_set.filter(lambda e, idx: idx>=(i*user_num_ts) and idx < user_num_ts*(i+1), with_indices=True)\n",
    "    user_data_list.append(train_loader)\n",
    "    server_data_list.append(test_loader)\n",
    "    # print(train_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2015, 1, 1, 0, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.strptime('2015-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (enc_embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(86, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=4, out_features=64, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dec_embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(86, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=4, out_features=64, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attn_layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (attention): AttentionLayer(\n",
       "          (inner_attention): DSAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x DecoderLayer(\n",
       "        (self_attention): AttentionLayer(\n",
       "          (inner_attention): DSAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (cross_attention): AttentionLayer(\n",
       "          (inner_attention): DSAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=64, out_features=86, bias=True)\n",
       "  )\n",
       "  (tau_learner): Projector(\n",
       "    (series_conv): Conv1d(96, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    (backbone): Sequential(\n",
       "      (0): Linear(in_features=172, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (delta_learner): Projector(\n",
       "    (series_conv): Conv1d(96, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    (backbone): Sequential(\n",
       "      (0): Linear(in_features=172, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=96, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ns_models import ns_Transformer\n",
    "server_model = ns_Transformer.Model(configs=args)\n",
    "server_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkenlvq\u001b[0m (\u001b[33mquanla\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2eb4ef9a6be4731b9511abaebd91675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112193773604102, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/qula0496/quan/Nonstationary_Transformers/wandb/run-20240611_143239-y2tur06q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20Traffic%20dataset/runs/y2tur06q' target=\"_blank\">Federated Non-Stationary Transformer on Traffic dataset</a></strong> to <a href='https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20Traffic%20dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20Traffic%20dataset' target=\"_blank\">https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20Traffic%20dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20Traffic%20dataset/runs/y2tur06q' target=\"_blank\">https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20Traffic%20dataset/runs/y2tur06q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "LR = 1e-3\n",
    "GLOBAL_EPOCHS = 30\n",
    "LOCAL_EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "L2_PENALTY = 0.0\n",
    "USER_RATIO = 0.1\n",
    "run = wandb.init(\n",
    "    # project name\n",
    "    project=\"Federated Non-Stationary Transformer on Traffic dataset\",\n",
    "    # experiment name\n",
    "    name=f\"Federated Non-Stationary Transformer on Traffic dataset\",\n",
    "    # Hyperparams\n",
    "    config={\n",
    "        \"dataset\": \"Traffic860\",\n",
    "        \"preprocess_type\": \"std\",\n",
    "        \"num_user\": n_users,\n",
    "        \"learning_rate\": LR,\n",
    "        \"global_epochs\": GLOBAL_EPOCHS,\n",
    "        \"local_epochs\": LOCAL_EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"num_gpus\": NUM_GPUS,\n",
    "        \"user_ratio\": USER_RATIO,\n",
    "        \"l2_penalty\": L2_PENALTY,\n",
    "        \"total_time_series\": 860,\n",
    "        \"detrending_data\": \"No\"\n",
    "    })\n",
    "\n",
    "config_wanb = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(server.test_loader[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de00bed10>\n",
      "Epoch: 1 cost time: 101.34275245666504\n",
      "Epoch: 2 cost time: 124.1690092086792\n",
      "Epoch: 3 cost time: 141.78920340538025\n",
      "Epoch: 4 cost time: 219.18019914627075\n",
      "Epoch: 5 cost time: 248.70971512794495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   3%|▎         | 1/30 [15:28<7:28:41, 928.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de032de40>\n",
      "Epoch: 1 cost time: 268.0891737937927\n",
      "Epoch: 2 cost time: 268.1454873085022\n",
      "Epoch: 3 cost time: 268.04471945762634\n",
      "Epoch: 4 cost time: 268.08643436431885\n",
      "Epoch: 5 cost time: 268.4338369369507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   7%|▋         | 2/30 [39:25<9:32:47, 1227.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de032c670>\n",
      "Epoch: 1 cost time: 270.0185079574585\n",
      "Epoch: 2 cost time: 268.4405107498169\n",
      "Epoch: 3 cost time: 268.97946333885193\n",
      "Epoch: 4 cost time: 269.42957305908203\n",
      "Epoch: 5 cost time: 268.668408870697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  10%|█         | 3/30 [1:03:27<9:56:26, 1325.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de00bed10>\n",
      "Epoch: 1 cost time: 267.57478761672974\n",
      "Epoch: 2 cost time: 268.8168635368347\n",
      "Epoch: 3 cost time: 268.4686107635498\n",
      "Epoch: 4 cost time: 267.8858699798584\n",
      "Epoch: 5 cost time: 268.0454511642456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  13%|█▎        | 4/30 [1:27:24<9:53:30, 1369.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfaf0>\n",
      "Epoch: 1 cost time: 268.0469174385071\n",
      "Epoch: 2 cost time: 266.80700755119324\n",
      "Epoch: 3 cost time: 267.5164170265198\n",
      "Epoch: 4 cost time: 267.89720940589905\n",
      "Epoch: 5 cost time: 268.63716340065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  17%|█▋        | 5/30 [1:51:20<9:40:37, 1393.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de032c670>\n",
      "Epoch: 1 cost time: 266.5175838470459\n",
      "Epoch: 2 cost time: 270.3297975063324\n",
      "Epoch: 3 cost time: 268.08816504478455\n",
      "Epoch: 4 cost time: 269.8669853210449\n",
      "Epoch: 5 cost time: 268.3721525669098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  20%|██        | 6/30 [2:15:20<9:23:42, 1409.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfca0>\n",
      "Epoch: 1 cost time: 267.99561643600464\n",
      "Epoch: 2 cost time: 268.6852569580078\n",
      "Epoch: 3 cost time: 268.0276529788971\n",
      "Epoch: 4 cost time: 267.24695658683777\n",
      "Epoch: 5 cost time: 267.55435395240784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  23%|██▎       | 7/30 [2:39:16<9:03:35, 1418.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfca0>\n",
      "Epoch: 1 cost time: 267.23994302749634\n",
      "Epoch: 2 cost time: 266.786616563797\n",
      "Epoch: 3 cost time: 267.93338537216187\n",
      "Epoch: 4 cost time: 269.43712973594666\n",
      "Epoch: 5 cost time: 267.2046947479248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  27%|██▋       | 8/30 [3:03:12<8:42:04, 1423.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfaf0>\n",
      "Epoch: 1 cost time: 267.90448784828186\n",
      "Epoch: 2 cost time: 265.96105694770813\n",
      "Epoch: 3 cost time: 266.7056746482849\n",
      "Epoch: 4 cost time: 268.00717782974243\n",
      "Epoch: 5 cost time: 266.7398443222046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  30%|███       | 9/30 [3:27:03<8:19:09, 1426.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de032c670>\n",
      "Epoch: 1 cost time: 267.9961369037628\n",
      "Epoch: 2 cost time: 268.25184202194214\n",
      "Epoch: 3 cost time: 266.5767912864685\n",
      "Epoch: 4 cost time: 266.47679829597473\n",
      "Epoch: 5 cost time: 266.7973954677582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  33%|███▎      | 10/30 [3:50:57<7:56:09, 1428.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de8a4fbe0>\n",
      "Epoch: 1 cost time: 267.93423342704773\n",
      "Epoch: 2 cost time: 267.82448410987854\n",
      "Epoch: 3 cost time: 269.09215211868286\n",
      "Epoch: 4 cost time: 267.1247043609619\n",
      "Epoch: 5 cost time: 267.2639651298523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  37%|███▋      | 11/30 [4:14:53<7:33:02, 1430.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfaf0>\n",
      "Epoch: 1 cost time: 268.51034235954285\n",
      "Epoch: 2 cost time: 267.7183291912079\n",
      "Epoch: 3 cost time: 269.0505886077881\n",
      "Epoch: 4 cost time: 268.1525363922119\n",
      "Epoch: 5 cost time: 268.70696234703064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  40%|████      | 12/30 [4:38:51<7:09:53, 1432.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfca0>\n",
      "Epoch: 1 cost time: 267.0425114631653\n",
      "Epoch: 2 cost time: 267.85798716545105\n",
      "Epoch: 3 cost time: 267.75190567970276\n",
      "Epoch: 4 cost time: 269.5083074569702\n",
      "Epoch: 5 cost time: 267.1441059112549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  43%|████▎     | 13/30 [5:02:47<6:46:14, 1433.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de00bed10>\n",
      "Epoch: 1 cost time: 269.28305435180664\n",
      "Epoch: 2 cost time: 265.87044167518616\n",
      "Epoch: 3 cost time: 267.29041385650635\n",
      "Epoch: 4 cost time: 268.5287766456604\n",
      "Epoch: 5 cost time: 267.75832772254944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  47%|████▋     | 14/30 [5:26:43<6:22:31, 1434.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfbe0>\n",
      "Epoch: 1 cost time: 267.56772327423096\n",
      "Epoch: 2 cost time: 268.0201759338379\n",
      "Epoch: 3 cost time: 267.7734775543213\n",
      "Epoch: 4 cost time: 267.54568433761597\n",
      "Epoch: 5 cost time: 266.2050840854645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  50%|█████     | 15/30 [5:50:36<5:58:32, 1434.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de032de40>\n",
      "Epoch: 1 cost time: 268.6424632072449\n",
      "Epoch: 2 cost time: 266.977915763855\n",
      "Epoch: 3 cost time: 267.81358647346497\n",
      "Epoch: 4 cost time: 268.67559003829956\n",
      "Epoch: 5 cost time: 267.8789002895355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  53%|█████▎    | 16/30 [6:14:33<5:34:49, 1434.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfca0>\n",
      "Epoch: 1 cost time: 266.44893527030945\n",
      "Epoch: 2 cost time: 267.80401253700256\n",
      "Epoch: 3 cost time: 268.27756357192993\n",
      "Epoch: 4 cost time: 268.2421410083771\n",
      "Epoch: 5 cost time: 268.2756950855255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  57%|█████▋    | 17/30 [6:38:28<5:10:56, 1435.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de032de40>\n",
      "Epoch: 1 cost time: 268.21003007888794\n",
      "Epoch: 2 cost time: 265.8067002296448\n",
      "Epoch: 3 cost time: 267.3744511604309\n",
      "Epoch: 4 cost time: 268.13149333000183\n",
      "Epoch: 5 cost time: 268.009215593338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  60%|██████    | 18/30 [7:02:22<4:46:55, 1434.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfca0>\n",
      "Epoch: 1 cost time: 267.37838792800903\n",
      "Epoch: 2 cost time: 266.5966246128082\n",
      "Epoch: 3 cost time: 267.2623028755188\n",
      "Epoch: 4 cost time: 266.77086210250854\n",
      "Epoch: 5 cost time: 266.9361734390259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  63%|██████▎   | 19/30 [7:26:14<4:22:52, 1433.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfaf0>\n",
      "Epoch: 1 cost time: 270.5017204284668\n",
      "Epoch: 2 cost time: 267.6655812263489\n",
      "Epoch: 3 cost time: 268.06391167640686\n",
      "Epoch: 4 cost time: 258.1458604335785\n",
      "Epoch: 5 cost time: 243.7772605419159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  67%|██████▋   | 20/30 [7:49:30<3:57:05, 1422.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfc10>\n",
      "Epoch: 1 cost time: 242.08266949653625\n",
      "Epoch: 2 cost time: 243.18963503837585\n",
      "Epoch: 3 cost time: 243.84461498260498\n",
      "Epoch: 4 cost time: 244.53249382972717\n",
      "Epoch: 5 cost time: 244.41789484024048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  70%|███████   | 21/30 [8:11:16<3:28:07, 1387.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de032c670>\n",
      "Epoch: 1 cost time: 243.323392868042\n",
      "Epoch: 2 cost time: 243.49038410186768\n",
      "Epoch: 3 cost time: 243.9791615009308\n",
      "Epoch: 4 cost time: 243.08340501785278\n",
      "Epoch: 5 cost time: 241.67659282684326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  73%|███████▎  | 22/30 [8:33:00<3:01:38, 1362.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de032c670>\n",
      "Epoch: 1 cost time: 243.21903610229492\n",
      "Epoch: 2 cost time: 244.724356174469\n",
      "Epoch: 3 cost time: 244.29496026039124\n",
      "Epoch: 4 cost time: 242.5067012310028\n",
      "Epoch: 5 cost time: 242.14469957351685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  77%|███████▋  | 23/30 [8:54:44<2:36:54, 1344.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfca0>\n",
      "Epoch: 1 cost time: 244.11835885047913\n",
      "Epoch: 2 cost time: 243.96760082244873\n",
      "Epoch: 3 cost time: 243.79419827461243\n",
      "Epoch: 4 cost time: 243.34554147720337\n",
      "Epoch: 5 cost time: 242.55182003974915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  80%|████████  | 24/30 [9:16:30<2:13:19, 1333.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de8a4fbe0>\n",
      "Epoch: 1 cost time: 241.52741694450378\n",
      "Epoch: 2 cost time: 241.8083803653717\n",
      "Epoch: 3 cost time: 242.57094812393188\n",
      "Epoch: 4 cost time: 242.37704467773438\n",
      "Epoch: 5 cost time: 242.1317708492279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  83%|████████▎ | 25/30 [9:38:08<1:50:12, 1322.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfaf0>\n",
      "Epoch: 1 cost time: 243.5994725227356\n",
      "Epoch: 2 cost time: 242.60570693016052\n",
      "Epoch: 3 cost time: 244.39579391479492\n",
      "Epoch: 4 cost time: 242.66039204597473\n",
      "Epoch: 5 cost time: 242.11198210716248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  87%|████████▋ | 26/30 [9:59:51<1:27:47, 1316.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfaf0>\n",
      "Epoch: 1 cost time: 242.7055540084839\n",
      "Epoch: 2 cost time: 242.94147372245789\n",
      "Epoch: 3 cost time: 242.6933286190033\n",
      "Epoch: 4 cost time: 243.71558117866516\n",
      "Epoch: 5 cost time: 243.13213324546814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  90%|█████████ | 27/30 [10:21:35<1:05:38, 1312.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de03cfca0>\n",
      "Epoch: 1 cost time: 243.60196089744568\n",
      "Epoch: 2 cost time: 243.72361969947815\n",
      "Epoch: 3 cost time: 243.22293496131897\n",
      "Epoch: 4 cost time: 244.29728484153748\n",
      "Epoch: 5 cost time: 243.9863567352295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  93%|█████████▎| 28/30 [10:43:20<43:41, 1310.64s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de01c03a0>\n",
      "Epoch: 1 cost time: 243.3594160079956\n",
      "Epoch: 2 cost time: 241.8831729888916\n",
      "Epoch: 3 cost time: 241.30721855163574\n",
      "Epoch: 4 cost time: 242.5002682209015\n",
      "Epoch: 5 cost time: 242.30870532989502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  97%|█████████▋| 29/30 [11:04:59<21:47, 1307.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7f8de02a1510>\n",
      "Epoch: 1 cost time: 243.30097317695618\n",
      "Epoch: 2 cost time: 243.493230342865\n",
      "Epoch: 3 cost time: 244.42128682136536\n",
      "Epoch: 4 cost time: 243.1486611366272\n",
      "Epoch: 5 cost time: 243.40658473968506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 30/30 [11:26:45<00:00, 1373.53s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "\n",
    "server = ServerNsTransformer(model=server_model, test_loader=server_data_list)\n",
    "\n",
    "user_list = []\n",
    "\n",
    "# Create users\n",
    "for i in range(config_wanb.num_user):\n",
    "    user_i = UserNsTransformer(train_loader=user_data_list[i], model=server_model, user_id=i, local_epochs=config_wanb.local_epochs)\n",
    "    user_list.append(user_i)\n",
    "\n",
    "for _ in tqdm(range(config_wanb.global_epochs), desc=f\"Progress\"):\n",
    "    # Distribute initial model to users\n",
    "    server.distribute_model(user_list)\n",
    "    \n",
    "    # Sub-sample users\n",
    "    sub_user_list = random.sample(user_list, int(config_wanb.user_ratio * config_wanb.num_user))\n",
    "\n",
    "    # Check the sub-sampled user and train model\n",
    "    users_loss = 0.0\n",
    "    for user in sub_user_list:\n",
    "        print(user)\n",
    "        user_loss = user.user_train(args)\n",
    "        users_loss += user_loss\n",
    "    # Aggregate weights on server\n",
    "    server.aggregate_weights(sub_user_list)\n",
    "\n",
    "    # Calulate avg loss on selected users\n",
    "    train_loss =  users_loss / len(sub_user_list)\n",
    "\n",
    "    total_mae = []\n",
    "    total_mse = []\n",
    "    for test_loader in server.test_loader:    \n",
    "        mae, mse, rmse, mape, mspe = server.model_eval(args=args, test_loader=test_loader)\n",
    "        total_mae.append(mae)\n",
    "        total_mse.append(mse)\n",
    "    \n",
    "    wandb.log({\"train_loss\": train_loss, \"mae\": sum(total_mae)/len(total_mae), 'rmse': sqrt(sum(total_mse)/len(total_mse))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.34313673,\n",
       " 0.38036826,\n",
       " 0.3625005,\n",
       " 0.3530789,\n",
       " 0.34848684,\n",
       " 0.27234304,\n",
       " 0.34942037,\n",
       " 0.39622217,\n",
       " 0.4255446,\n",
       " 0.49193102]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_mae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
