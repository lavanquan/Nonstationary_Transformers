{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/qula0496/quan/Nonstationary_Transformers/ns_models'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qula0496/quan/Nonstationary_Transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qula0496/quan/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gpu_id = '1'\n",
    "n_users = 10\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_id\n",
    "dataset_name = 'trentino'\n",
    "sub_set_name = 'internet'\n",
    "series_type = 'hourly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import *\n",
    "from utils.model_utils import *\n",
    "# from utils.koopman_utils import *\n",
    "from modules.serverbase import *\n",
    "from modules.userbase import *\n",
    "from modules.servernsTransformer import *\n",
    "from modules.usernsTranformer import *\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.cuda.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "def preprocess(data, std=True):\n",
    "    '''\n",
    "    Function to do preprocess for input data\n",
    "    inputs:\n",
    "        + data: pandas.DataFrame\n",
    "    outputs:\n",
    "        + preprocessed_data: pandas.DataFrame\n",
    "    '''\n",
    "    if std:\n",
    "        scaler = StandardScaler()\n",
    "        temp = scaler.fit_transform(data)\n",
    "    else:\n",
    "        scaler = MinMaxScaler()\n",
    "        temp = scaler.fit_transform(data)\n",
    "    processed_data = pd.DataFrame(temp, index=data.index, columns = data.columns)\n",
    "    # processed_data = processed_data.to_numpy()\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gridID</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>...</th>\n",
       "      <th>11217</th>\n",
       "      <th>11218</th>\n",
       "      <th>11219</th>\n",
       "      <th>11220</th>\n",
       "      <th>11335</th>\n",
       "      <th>11336</th>\n",
       "      <th>11337</th>\n",
       "      <th>11452</th>\n",
       "      <th>11453</th>\n",
       "      <th>11454</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>startTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-11-01 00:00:00</th>\n",
       "      <td>0.070513</td>\n",
       "      <td>0.079877</td>\n",
       "      <td>0.138498</td>\n",
       "      <td>0.079829</td>\n",
       "      <td>0.086237</td>\n",
       "      <td>0.081288</td>\n",
       "      <td>0.088334</td>\n",
       "      <td>0.153213</td>\n",
       "      <td>0.122837</td>\n",
       "      <td>0.126910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038866</td>\n",
       "      <td>0.015604</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.023932</td>\n",
       "      <td>0.060878</td>\n",
       "      <td>0.019350</td>\n",
       "      <td>0.020722</td>\n",
       "      <td>0.070202</td>\n",
       "      <td>0.055282</td>\n",
       "      <td>0.019964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 01:00:00</th>\n",
       "      <td>0.049713</td>\n",
       "      <td>0.060607</td>\n",
       "      <td>0.092762</td>\n",
       "      <td>0.048852</td>\n",
       "      <td>0.053276</td>\n",
       "      <td>0.066329</td>\n",
       "      <td>0.069117</td>\n",
       "      <td>0.109108</td>\n",
       "      <td>0.088937</td>\n",
       "      <td>0.093735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.012212</td>\n",
       "      <td>0.021476</td>\n",
       "      <td>0.014672</td>\n",
       "      <td>0.035150</td>\n",
       "      <td>0.024047</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.038681</td>\n",
       "      <td>0.033044</td>\n",
       "      <td>0.028545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 02:00:00</th>\n",
       "      <td>0.059755</td>\n",
       "      <td>0.064257</td>\n",
       "      <td>0.056337</td>\n",
       "      <td>0.050885</td>\n",
       "      <td>0.064577</td>\n",
       "      <td>0.073372</td>\n",
       "      <td>0.063995</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.075936</td>\n",
       "      <td>0.092412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.008558</td>\n",
       "      <td>0.013205</td>\n",
       "      <td>0.013320</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.013948</td>\n",
       "      <td>0.013838</td>\n",
       "      <td>0.027604</td>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.014725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 03:00:00</th>\n",
       "      <td>0.052892</td>\n",
       "      <td>0.053441</td>\n",
       "      <td>0.038942</td>\n",
       "      <td>0.046973</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.056657</td>\n",
       "      <td>0.049539</td>\n",
       "      <td>0.064613</td>\n",
       "      <td>0.054763</td>\n",
       "      <td>0.058460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013630</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>0.026692</td>\n",
       "      <td>0.007357</td>\n",
       "      <td>0.011778</td>\n",
       "      <td>0.031836</td>\n",
       "      <td>0.020744</td>\n",
       "      <td>0.016335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 04:00:00</th>\n",
       "      <td>0.040440</td>\n",
       "      <td>0.055874</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.048165</td>\n",
       "      <td>0.053330</td>\n",
       "      <td>0.060869</td>\n",
       "      <td>0.050811</td>\n",
       "      <td>0.061678</td>\n",
       "      <td>0.040994</td>\n",
       "      <td>0.041741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010115</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.010488</td>\n",
       "      <td>0.026558</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.010915</td>\n",
       "      <td>0.032037</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>0.015189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gridID                  38        39        40        154       155    \\\n",
       "startTime                                                               \n",
       "2013-11-01 00:00:00  0.070513  0.079877  0.138498  0.079829  0.086237   \n",
       "2013-11-01 01:00:00  0.049713  0.060607  0.092762  0.048852  0.053276   \n",
       "2013-11-01 02:00:00  0.059755  0.064257  0.056337  0.050885  0.064577   \n",
       "2013-11-01 03:00:00  0.052892  0.053441  0.038942  0.046973  0.047012   \n",
       "2013-11-01 04:00:00  0.040440  0.055874  0.018405  0.048165  0.053330   \n",
       "\n",
       "gridID                  156       157       158       159       160    ...  \\\n",
       "startTime                                                              ...   \n",
       "2013-11-01 00:00:00  0.081288  0.088334  0.153213  0.122837  0.126910  ...   \n",
       "2013-11-01 01:00:00  0.066329  0.069117  0.109108  0.088937  0.093735  ...   \n",
       "2013-11-01 02:00:00  0.073372  0.063995  0.088428  0.075936  0.092412  ...   \n",
       "2013-11-01 03:00:00  0.056657  0.049539  0.064613  0.054763  0.058460  ...   \n",
       "2013-11-01 04:00:00  0.060869  0.050811  0.061678  0.040994  0.041741  ...   \n",
       "\n",
       "gridID                  11217     11218     11219     11220     11335  \\\n",
       "startTime                                                               \n",
       "2013-11-01 00:00:00  0.038866  0.015604  0.019802  0.023932  0.060878   \n",
       "2013-11-01 01:00:00  0.024250  0.012212  0.021476  0.014672  0.035150   \n",
       "2013-11-01 02:00:00  0.017183  0.008558  0.013205  0.013320  0.023523   \n",
       "2013-11-01 03:00:00  0.013630  0.004955  0.006178  0.009959  0.026692   \n",
       "2013-11-01 04:00:00  0.010115  0.005666  0.008015  0.010488  0.026558   \n",
       "\n",
       "gridID                  11336     11337     11452     11453     11454  \n",
       "startTime                                                              \n",
       "2013-11-01 00:00:00  0.019350  0.020722  0.070202  0.055282  0.019964  \n",
       "2013-11-01 01:00:00  0.024047  0.025600  0.038681  0.033044  0.028545  \n",
       "2013-11-01 02:00:00  0.013948  0.013838  0.027604  0.022939  0.014725  \n",
       "2013-11-01 03:00:00  0.007357  0.011778  0.031836  0.020744  0.016335  \n",
       "2013-11-01 04:00:00  0.008772  0.010915  0.032037  0.019349  0.015189  \n",
       "\n",
       "[5 rows x 6259 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = f\"./dataset/{dataset_name}/{dataset_name}_{sub_set_name}_{series_type}.csv\"\n",
    "raw_data = pd.read_csv(file_path)\n",
    "raw_data = raw_data.pivot(index='startTime', columns='gridID', values=sub_set_name)\n",
    "raw_data = raw_data.fillna(0)\n",
    "raw_data = preprocess(raw_data, std=False)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gridID</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>...</th>\n",
       "      <th>11217</th>\n",
       "      <th>11218</th>\n",
       "      <th>11219</th>\n",
       "      <th>11220</th>\n",
       "      <th>11335</th>\n",
       "      <th>11336</th>\n",
       "      <th>11337</th>\n",
       "      <th>11452</th>\n",
       "      <th>11453</th>\n",
       "      <th>11454</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>startTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-11-01 00:00:00</th>\n",
       "      <td>0.070513</td>\n",
       "      <td>0.079877</td>\n",
       "      <td>0.138498</td>\n",
       "      <td>0.079829</td>\n",
       "      <td>0.086237</td>\n",
       "      <td>0.081288</td>\n",
       "      <td>0.088334</td>\n",
       "      <td>0.153213</td>\n",
       "      <td>0.122837</td>\n",
       "      <td>0.126910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038866</td>\n",
       "      <td>0.015604</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.023932</td>\n",
       "      <td>0.060878</td>\n",
       "      <td>0.019350</td>\n",
       "      <td>0.020722</td>\n",
       "      <td>0.070202</td>\n",
       "      <td>0.055282</td>\n",
       "      <td>0.019964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 01:00:00</th>\n",
       "      <td>0.049713</td>\n",
       "      <td>0.060607</td>\n",
       "      <td>0.092762</td>\n",
       "      <td>0.048852</td>\n",
       "      <td>0.053276</td>\n",
       "      <td>0.066329</td>\n",
       "      <td>0.069117</td>\n",
       "      <td>0.109108</td>\n",
       "      <td>0.088937</td>\n",
       "      <td>0.093735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.012212</td>\n",
       "      <td>0.021476</td>\n",
       "      <td>0.014672</td>\n",
       "      <td>0.035150</td>\n",
       "      <td>0.024047</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.038681</td>\n",
       "      <td>0.033044</td>\n",
       "      <td>0.028545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 02:00:00</th>\n",
       "      <td>0.059755</td>\n",
       "      <td>0.064257</td>\n",
       "      <td>0.056337</td>\n",
       "      <td>0.050885</td>\n",
       "      <td>0.064577</td>\n",
       "      <td>0.073372</td>\n",
       "      <td>0.063995</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.075936</td>\n",
       "      <td>0.092412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.008558</td>\n",
       "      <td>0.013205</td>\n",
       "      <td>0.013320</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.013948</td>\n",
       "      <td>0.013838</td>\n",
       "      <td>0.027604</td>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.014725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 03:00:00</th>\n",
       "      <td>0.052892</td>\n",
       "      <td>0.053441</td>\n",
       "      <td>0.038942</td>\n",
       "      <td>0.046973</td>\n",
       "      <td>0.047012</td>\n",
       "      <td>0.056657</td>\n",
       "      <td>0.049539</td>\n",
       "      <td>0.064613</td>\n",
       "      <td>0.054763</td>\n",
       "      <td>0.058460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013630</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>0.026692</td>\n",
       "      <td>0.007357</td>\n",
       "      <td>0.011778</td>\n",
       "      <td>0.031836</td>\n",
       "      <td>0.020744</td>\n",
       "      <td>0.016335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01 04:00:00</th>\n",
       "      <td>0.040440</td>\n",
       "      <td>0.055874</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.048165</td>\n",
       "      <td>0.053330</td>\n",
       "      <td>0.060869</td>\n",
       "      <td>0.050811</td>\n",
       "      <td>0.061678</td>\n",
       "      <td>0.040994</td>\n",
       "      <td>0.041741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010115</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.010488</td>\n",
       "      <td>0.026558</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.010915</td>\n",
       "      <td>0.032037</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>0.015189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gridID                  38        39        40        154       155    \\\n",
       "startTime                                                               \n",
       "2013-11-01 00:00:00  0.070513  0.079877  0.138498  0.079829  0.086237   \n",
       "2013-11-01 01:00:00  0.049713  0.060607  0.092762  0.048852  0.053276   \n",
       "2013-11-01 02:00:00  0.059755  0.064257  0.056337  0.050885  0.064577   \n",
       "2013-11-01 03:00:00  0.052892  0.053441  0.038942  0.046973  0.047012   \n",
       "2013-11-01 04:00:00  0.040440  0.055874  0.018405  0.048165  0.053330   \n",
       "\n",
       "gridID                  156       157       158       159       160    ...  \\\n",
       "startTime                                                              ...   \n",
       "2013-11-01 00:00:00  0.081288  0.088334  0.153213  0.122837  0.126910  ...   \n",
       "2013-11-01 01:00:00  0.066329  0.069117  0.109108  0.088937  0.093735  ...   \n",
       "2013-11-01 02:00:00  0.073372  0.063995  0.088428  0.075936  0.092412  ...   \n",
       "2013-11-01 03:00:00  0.056657  0.049539  0.064613  0.054763  0.058460  ...   \n",
       "2013-11-01 04:00:00  0.060869  0.050811  0.061678  0.040994  0.041741  ...   \n",
       "\n",
       "gridID                  11217     11218     11219     11220     11335  \\\n",
       "startTime                                                               \n",
       "2013-11-01 00:00:00  0.038866  0.015604  0.019802  0.023932  0.060878   \n",
       "2013-11-01 01:00:00  0.024250  0.012212  0.021476  0.014672  0.035150   \n",
       "2013-11-01 02:00:00  0.017183  0.008558  0.013205  0.013320  0.023523   \n",
       "2013-11-01 03:00:00  0.013630  0.004955  0.006178  0.009959  0.026692   \n",
       "2013-11-01 04:00:00  0.010115  0.005666  0.008015  0.010488  0.026558   \n",
       "\n",
       "gridID                  11336     11337     11452     11453     11454  \n",
       "startTime                                                              \n",
       "2013-11-01 00:00:00  0.019350  0.020722  0.070202  0.055282  0.019964  \n",
       "2013-11-01 01:00:00  0.024047  0.025600  0.038681  0.033044  0.028545  \n",
       "2013-11-01 02:00:00  0.013948  0.013838  0.027604  0.022939  0.014725  \n",
       "2013-11-01 03:00:00  0.007357  0.011778  0.031836  0.020744  0.016335  \n",
       "2013-11-01 04:00:00  0.008772  0.010915  0.032037  0.019349  0.015189  \n",
       "\n",
       "[5 rows x 6259 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt: write pandas to csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "raw_data.rename(columns={'startTime': 'date'}, inplace=True)\n",
    "raw_data.to_csv(f\"./dataset/{dataset_name}/{sub_set_name}.csv\", index_label='date')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "# download_elec_dataset()\n",
    "\n",
    "# # Clean dataset\n",
    "# elec_data = clean_elec()\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# Std_normalization = 1\n",
    "# if Std_normalization:\n",
    "#     scaler = StandardScaler()\n",
    "#     temp = scaler.fit_transform(elec_data)\n",
    "#     norm_means = scaler.mean_\n",
    "#     norm_std = scaler.scale_\n",
    "# else:\n",
    "#     scaler = MinMaxScaler()\n",
    "#     temp = scaler.fit_transform(elec_data)\n",
    "\n",
    "# elec_data = pd.DataFrame(elec_data, index=elec_data.index, columns = elec_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'internet.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ns_models.ns_TransformerConfig import NS_TransformerConfig\n",
    "user_num_ts = int(raw_data.shape[1] / n_users)\n",
    "args = NS_TransformerConfig()\n",
    "args.devices = gpu_id\n",
    "args.enc_in = user_num_ts\n",
    "args.dec_in = user_num_ts\n",
    "args.c_out = user_num_ts\n",
    "args.root_path='./dataset/trentino/'\n",
    "args.data_path='internet.csv'\n",
    "args.data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data_provider.data_factory import *\n",
    "from data_provider.data_loader import *\n",
    "\n",
    "test_data, test_loader = data_provider(args, flag='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 6259)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 625)\n",
      "(96, 625)\n",
      "(96, 625)\n",
      "(96, 625)\n",
      "(96, 625)\n",
      "(96, 625)\n",
      "(96, 625)\n",
      "(96, 625)\n",
      "(96, 625)\n",
      "(96, 634)\n"
     ]
    }
   ],
   "source": [
    "user_data_list = []\n",
    "server_data_list = []\n",
    "for i in range(n_users):\n",
    "    train_data, train_loader = data_provider(args, flag='train', start=i*user_num_ts+1, end=min(user_num_ts*(i+1)+1, raw_data.shape[1]+1))\n",
    "    test_data, test_loader = data_provider(args, flag='test', start=i*user_num_ts+1, end=min(user_num_ts*(i+1)+1, raw_data.shape[1]+1))\n",
    "    # user_data = train_set.filter(lambda e, idx: idx>=(i*user_num_ts) and idx < user_num_ts*(i+1), with_indices=True)\n",
    "    user_data_list.append(train_loader)\n",
    "    server_data_list.append(test_loader)\n",
    "    print(train_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (enc_embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(625, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=4, out_features=64, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dec_embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(625, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TimeFeatureEmbedding(\n",
       "      (embed): Linear(in_features=4, out_features=64, bias=False)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attn_layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (attention): AttentionLayer(\n",
       "          (inner_attention): DSAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x DecoderLayer(\n",
       "        (self_attention): AttentionLayer(\n",
       "          (inner_attention): DSAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (cross_attention): AttentionLayer(\n",
       "          (inner_attention): DSAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (key_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (value_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (out_projection): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=64, out_features=625, bias=True)\n",
       "  )\n",
       "  (tau_learner): Projector(\n",
       "    (series_conv): Conv1d(96, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    (backbone): Sequential(\n",
       "      (0): Linear(in_features=1250, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (delta_learner): Projector(\n",
       "    (series_conv): Conv1d(96, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "    (backbone): Sequential(\n",
       "      (0): Linear(in_features=1250, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=96, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ns_models import ns_Transformer\n",
    "server_model = ns_Transformer.Model(configs=args)\n",
    "server_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup WANDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkenlvq\u001b[0m (\u001b[33mquanla\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b8439ca506453ca245fd263bea8073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113414934111967, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/qula0496/quan/Nonstationary_Transformers/wandb/run-20240703_171202-3d1g5bex</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20Milan%20dataset/runs/3d1g5bex' target=\"_blank\">Federated Non-Stationary Transformer on Trentino Internet dataset</a></strong> to <a href='https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20Milan%20dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20Milan%20dataset' target=\"_blank\">https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20Milan%20dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20Milan%20dataset/runs/3d1g5bex' target=\"_blank\">https://wandb.ai/quanla/Federated%20Non-Stationary%20Transformer%20on%20Milan%20dataset/runs/3d1g5bex</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "LR = 1e-3\n",
    "GLOBAL_EPOCHS = 50\n",
    "LOCAL_EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "L2_PENALTY = 0.0\n",
    "USER_RATIO = 0.2\n",
    "run = wandb.init(\n",
    "    # project name\n",
    "    project=\"Federated Non-Stationary Transformer on Milan dataset\",\n",
    "    # experiment name\n",
    "    name=f\"Federated Non-Stationary Transformer on Trentino Internet dataset\",\n",
    "    # Hyperparams\n",
    "    config={\n",
    "        \"dataset\": \"Milan Call\",\n",
    "        \"preprocess_type\": \"std\",\n",
    "        \"num_user\": n_users,\n",
    "        \"learning_rate\": LR,\n",
    "        \"global_epochs\": GLOBAL_EPOCHS,\n",
    "        \"local_epochs\": LOCAL_EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"num_gpus\": NUM_GPUS,\n",
    "        \"user_ratio\": USER_RATIO,\n",
    "        \"l2_penalty\": L2_PENALTY,\n",
    "        \"total_time_series\": 10000,\n",
    "        \"detrending_data\": \"No\"\n",
    "    })\n",
    "\n",
    "config_wanb = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<modules.usernsTranformer.UserNsTransformer object at 0x7fa732aa10f0>\n",
      "Epoch: 1 cost time: 3.9608805179595947\n",
      "Epoch: 2 cost time: 2.6356217861175537\n",
      "Epoch: 3 cost time: 2.5792269706726074\n",
      "Epoch: 4 cost time: 2.6608664989471436\n",
      "Epoch: 5 cost time: 2.6010007858276367\n",
      "<modules.usernsTranformer.UserNsTransformer object at 0x7fa732aa1060>\n",
      "Epoch: 1 cost time: 2.545443058013916\n",
      "Epoch: 2 cost time: 2.5215184688568115\n",
      "Epoch: 3 cost time: 2.4727935791015625\n",
      "Epoch: 4 cost time: 2.924386739730835\n",
      "Epoch: 5 cost time: 3.210320472717285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/50 [00:42<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1268 and 1250x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m total_mse \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_loader \u001b[38;5;129;01min\u001b[39;00m server\u001b[38;5;241m.\u001b[39mtest_loader:    \n\u001b[0;32m---> 36\u001b[0m     mae, mse, rmse, mape, mspe \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     total_mae\u001b[38;5;241m.\u001b[39mappend(mae)\n\u001b[1;32m     38\u001b[0m     total_mse\u001b[38;5;241m.\u001b[39mappend(mse)\n",
      "File \u001b[0;32m~/quan/Nonstationary_Transformers/modules/servernsTransformer.py:38\u001b[0m, in \u001b[0;36mServerNsTransformer.model_eval\u001b[0;34m(self, args, test_loader, test)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39moutput_attention:\n\u001b[0;32m---> 38\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x_mark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_inp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y_mark\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/quan/Nonstationary_Transformers/ns_models/ns_Transformer.py:104\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\u001b[0m\n\u001b[1;32m    101\u001b[0m x_enc \u001b[38;5;241m=\u001b[39m x_enc \u001b[38;5;241m/\u001b[39m std_enc\n\u001b[1;32m    102\u001b[0m x_dec_new \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x_enc[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_len: , :], torch\u001b[38;5;241m.\u001b[39mzeros_like(x_dec[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_len:, :])], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(x_enc\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m--> 104\u001b[0m tau \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtau_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_enc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexp()     \u001b[38;5;66;03m# B x S x E, B x 1 x E -> B x 1, positive scalar    \u001b[39;00m\n\u001b[1;32m    105\u001b[0m delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelta_learner(x_raw, mean_enc)      \u001b[38;5;66;03m# B x S x E, B x 1 x E -> B x S\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Model Inference\u001b[39;00m\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/quan/Nonstationary_Transformers/ns_models/ns_Transformer.py:33\u001b[0m, in \u001b[0;36mProjector.forward\u001b[0;34m(self, x, stats)\u001b[0m\n\u001b[1;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, stats], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# B x 2 x E\u001b[39;00m\n\u001b[1;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# B x 2E\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m       \u001b[38;5;66;03m# B x O\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/quan/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1268 and 1250x64)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "\n",
    "server = ServerNsTransformer(model=server_model, test_loader=server_data_list)\n",
    "\n",
    "user_list = []\n",
    "\n",
    "# Create users\n",
    "for i in range(config_wanb.num_user):\n",
    "    user_i = UserNsTransformer(train_loader=user_data_list[i], model=server_model, user_id=i, local_epochs=config_wanb.local_epochs)\n",
    "    user_list.append(user_i)\n",
    "\n",
    "for _ in tqdm(range(config_wanb.global_epochs), desc=f\"Progress\"):\n",
    "    # Distribute initial model to users\n",
    "    server.distribute_model(user_list)\n",
    "    \n",
    "    # Sub-sample users\n",
    "    sub_user_list = random.sample(user_list, int(config_wanb.user_ratio * config_wanb.num_user))\n",
    "\n",
    "    # Check the sub-sampled user and train model\n",
    "    users_loss = 0.0\n",
    "    for user in sub_user_list:\n",
    "        print(user)\n",
    "        user_loss = user.user_train(args)\n",
    "        users_loss += user_loss\n",
    "    # Aggregate weights on server\n",
    "    server.aggregate_weights(sub_user_list)\n",
    "\n",
    "    # Calulate avg loss on selected users\n",
    "    train_loss =  users_loss / len(sub_user_list)\n",
    "\n",
    "    total_mae = []\n",
    "    total_mse = []\n",
    "    for test_loader in server.test_loader:    \n",
    "        mae, mse, rmse, mape, mspe = server.model_eval(args=args, test_loader=test_loader)\n",
    "        total_mae.append(mae)\n",
    "        total_mse.append(mse)\n",
    "    \n",
    "    wandb.log({\"train_loss\": train_loss, \"mae\": sum(total_mae)/len(total_mae), 'rmse': sqrt(sum(total_mse)/len(total_mse))})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
